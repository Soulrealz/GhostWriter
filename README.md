# Agentic Software Factory (Template)

> A plug-and-play template for building complex, multi-agent software systems using a **Parent Subgraph Architecture** and **Context Engineering**.

This repository moves beyond simple "chatbots" and massive system prompts. By treating AI as a systems engineering pipeline, this factory uses deterministic routing, dynamic skill loading, and graph-based memory to safely generate, review, and test complex software.

---

## The Tech Stack (What & Why)

| Role | Technology | Purpose in the Factory |
| :--- | :--- | :--- |
| **The Brains** | **Gemini / Claude SDKs** | Powers the individual cognitive nodes. Chosen for their native tool-calling, robust reasoning, and large context windows. |
| **The Rules** | **NotebookLM** | Our "Chief Architect." Used off-line to digest massive PDFs/whitepapers and generate lightweight `SKILL.md` files for the agents. |
| **The Orchestrator** | **LangGraph** | The core routing engine. Uses a "Parent Subgraph" architecture to separate the *Global State* (project goals) from the *Private State* (agents arguing over code). |
| **The Memory** | **Neo4j (GraphRAG)** | Long-term memory. Maps relationships between previous bugs, architectural decisions, and code files so the factory learns over time. |
| **The Overseer** | **LangSmith** | Complete observability. Traces every token, tool call, and agent thought process to debug AI hallucinations easily. |
| **Execution** | **Local Machine** *(E2B pending)* | Tests and compiles code natively. *(Note: Cloud-isolated E2B sandboxes are planned for future safe-execution upgrades).* |

---

## Core Architecture: The Flow

This template operates on the principle of **Progressive Disclosure**. Agents do not start with the entire codebase in their prompt. Instead, context is loaded dynamically.

1. **Initialization:** The user defines the Global State (e.g., "Build the L1 Vault smart contract").
2. **Routing:** The LangGraph **Parent Graph** reads the request and routes it to the appropriate **Child Subgraph** (e.g., the `smart_contract_node`).
3. **Skill Loading:** The child node wakes up, checks its available tools, and dynamically loads only the specific instructions from the `.skills/` directory (e.g., `ccip_messaging_skill.md`) it needs for the task.
4. **Execution & Consensus:** Internal agents within the subgraph write, review, and locally test the code (Private State).
5. **Handoff:** The subgraph returns *only* the finalized artifacts (e.g., compiled ABIs and deployment scripts) back to the Parent Graph's Global State.

---

## Proposed Folder Structure

```text
├── .skills/                 # Generated by NotebookLM (Dynamic agent context)
│   ├── core_architecture/
│   └── domain_specific/
├── src/
│   ├── agents/              # Gemini/Claude SDK agent definitions and prompts
│   ├── graphs/              # LangGraph.js orchestration logic
│   │   ├── parentGraph.ts   # The main routing graph
│   │   └── subgraphs/       # Domain-specific isolated graphs (e.g., frontend, contracts)
│   ├── memory/              # Neo4j GraphRAG connection and query logic
│   ├── schema/              # Zod schemas defining Global and Private States
│   └── tools/               # Custom tools (e.g., file system readers, API fetchers)
├── tests/                   # Jest/Vitest testing suites for graph routing
├── .env.example             # API keys template
├── package.json             # TypeScript/Node.js dependencies
├── tsconfig.json            # Strict TypeScript configuration
└── README.md
```

## Known Limitations

Because this is a highly opinionated, systems-level architecture, please be aware of the following constraints before building:

1. **SDK Lock-in**: This template relies heavily on the specific tool-calling paradigms of the Gemini and Claude SDKs. Dropping in a generic OpenAI or local Ollama model will break the native schema validation without writing custom wrapper classes.

2. **Manual Skill Generation**: NotebookLM does not currently have a native programmatic API. Converting whitepapers into .skills/ files requires a "Human-in-the-loop" to manually export the artifacts from NotebookLM and place them into the repo.

3. **Local Execution Risks**: Until E2B sandboxing is integrated, the agents will execute test commands (e.g., `forge test` or `npm run build`) directly on your local machine. Ensure agents are running in a constrained local environment or Docker container to prevent accidental system modifications.

4. **Context Collisions**: If multiple subgraphs attempt to write to the same file simultaneously without the LangGraph Parent managing a strict lock/queue, race conditions will occur.